import json
import re
import logging
from pathlib import Path
import argparse
from unstructured.partition.pdf import partition_pdf

# ========= æ—¥å¿—é…ç½® =========
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# ========= å¤šä¹¦ç±æ”¯æŒé…ç½® =========
BOOKS = {
    "æ—¥æœ¬èœ¡çƒ›å›¾æŠ€æœ¯": {
        "pdf": "file/æ—¥æœ¬èœ¡çƒ›å›¾æŠ€æœ¯.pdf",
        "keywords": ["Kçº¿", "å½¢æ€", "æŒ‡æ ‡", "è¶‹åŠ¿", "åè½¬", "çªç ´", "æ”¯æ’‘", "é˜»åŠ›", "æˆäº¤é‡"],
        "source": "æ—¥æœ¬èœ¡çƒ›å›¾æŠ€æœ¯"
    },
    "é‡‘èå¸‚åœºæŠ€æœ¯åˆ†æ": {
        "pdf": "file/å¸‚åœºæŠ€æœ¯åˆ†æ.pdf",
        "keywords": ["è¶‹åŠ¿", "æ”¯æ’‘", "é˜»åŠ›", "åè½¬", "çªç ´", "Kçº¿", "æŠ€æœ¯æŒ‡æ ‡", "ç§»åŠ¨å¹³å‡çº¿", "MACD", "RSI"],
        "source": "é‡‘èå¸‚åœºæŠ€æœ¯åˆ†æ"
    }
}

# ========= å·¥å…·å‡½æ•° =========
def is_valid(text, keywords):
    if not (20 <= len(text) <= 500):
        return False
    if not any(kw in text for kw in keywords):
        return False
    if re.search(r"(å…è´£å£°æ˜|ç‰ˆæƒæ‰€æœ‰|æ‰«ç |www|http|å‡ºç‰ˆç¤¾)", text):
        return False
    return True

def extract_chapter_title(text):
    match = re.match(r"^(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+ç« )", text.strip())
    return match.group(1) if match else None

def extract_section_title(text):
    if len(text.strip()) <= 30 and any(kw in text for kw in ["å½¢æ€", "æ¨¡å‹", "Kçº¿", "è¶‹åŠ¿", "æŒ‡æ ‡"]):
        return text.strip()
    return None

# ========= ä¸»æå–é€»è¾‘ =========
def process_book(book_name, config, debug=False):
    pdf_path = Path(config["pdf"])
    if not pdf_path.exists():
        logging.error(f"æ‰¾ä¸åˆ°PDFæ–‡ä»¶ï¼š{pdf_path}")
        return

    logging.info(f"ğŸ“˜ å¼€å§‹å¤„ç†: {pdf_path.name}")

    elements = partition_pdf(filename=str(pdf_path), strategy="fast")
    results = []
    chapter = None
    section = None

    for element in elements:
        text = element.text.strip()
        if debug:
            logging.debug(f"ğŸ” æå–æ–‡æœ¬: {text[:50]}")

        if not text:
            continue

        chapter_title = extract_chapter_title(text)
        if chapter_title:
            chapter = chapter_title
            continue

        section_title = extract_section_title(text)
        if section_title:
            section = section_title
            continue

        if not is_valid(text, config["keywords"]):
            if debug:
                logging.debug(f"âŒ æ— æ•ˆæ–‡æœ¬: {text[:50]}")
            continue

        results.append({
            "text": text,
            "page": element.metadata.page_number,
            "chapter": chapter,
            "section_title": section,
            "source": config["source"]
        })

    output_path = Path("data") / f"{book_name}_term_et_action_input_v8.jsonl"
    with open(output_path, "w", encoding="utf-8") as f:
        for item in results:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

    logging.info(f"âœ… {book_name} æå–å®Œæˆï¼Œå…± {len(results)} æ¡è®°å½•ï¼Œå·²å†™å…¥ï¼š{output_path}")

# ========= ä¸»å…¥å£ =========
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--debug", action="store_true", help="æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼")
    args = parser.parse_args()

    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)

    for name, cfg in BOOKS.items():
        logging.info(f"ğŸ“š æ­£åœ¨å¤„ç†ä¹¦ç±ï¼š{name}")
        process_book(name, cfg, debug=args.debug)